version: "3.9"
name: formbot

networks:
  backend:

volumes:
  mongo_data:
  airflow_postgres_data:

services:
  mongodb:
    image: mongo:6
    container_name: mongodb
    ports: ["27017:27017"]
    volumes:
      - mongo_data:/data/db
    healthcheck:
      test: ["CMD", "mongosh", "--quiet", "--eval", "db.runCommand({ ping: 1 })"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: [backend]

  api:
    build: ./api
    container_name: api
    env_file: .env
    environment:
      MONGODB_URI: mongodb://mongodb:27017/forms
      API_PORT: 8000
      OPENAI_MODEL: gpt-4o-mini
      CORS_ORIGINS: "*"
      AWS_REGION: ${AWS_REGION}
      FORMS_BUCKET: ${FORMS_BUCKET}
      S3_ENDPOINT_URL: ${S3_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    volumes:
      - ./api/app:/app/app:rw
    depends_on:
      mongodb:
        condition: service_healthy
    ports: ["8000:8000"]
    networks: [backend]
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

  frontend:
    build:
      context: ./frontend
      target: dev
    container_name: frontend
    env_file: .env
    environment:
      NEXT_PUBLIC_API_BASE_URL: http://localhost:8000
      NODE_ENV: development
    volumes:
      - ./frontend:/app:rw
      - /app/node_modules
      - /app/.next
    ports: ["3000:3000"]
    depends_on: [api]
    networks: [backend]
    command: ["npm", "run", "dev"]

  # Crawler service đã được quản lý bởi Airflow (crawler_dag)
  #   crawler:
  #     build: ./crawler
  #     container_name: crawler
  #     env_file: .env
  #     environment:
  #       AWS_REGION: ${AWS_REGION}
  #       FORMS_BUCKET: ${FORMS_BUCKET}
  #       S3_ENDPOINT_URL: ${S3_ENDPOINT_URL}
  #     volumes:
  #       - ./crawler/app:/app/app:rw
  #     command: ["python", "-m", "app.main", "--cron=0 3 * * *"]
  #     networks: [backend]

  worker:
    build: ./worker
    container_name: worker
    env_file: .env
    volumes:
      - ./worker/app:/app/app:rw
    environment:
      AWS_REGION: ${AWS_REGION}
      FORMS_BUCKET: ${FORMS_BUCKET}
      S3_ENDPOINT_URL: ${S3_ENDPOINT_URL}
      FORMS_QUEUE_URL: ${FORMS_QUEUE_URL}
      MONGODB_URI: mongodb://mongodb:27017/forms
    depends_on:
      mongodb:
        condition: service_healthy
    networks: [backend]

  # Airflow PostgreSQL database
  airflow_postgres:
    image: postgres:15
    container_name: airflow_postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: [backend]

  # Airflow Redis (for Celery executor if needed)
  airflow_redis:
    image: redis:7
    container_name: airflow_redis
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: [backend]

  # Airflow webserver
  airflow_webserver:
    build: ./airflow
    container_name: airflow_webserver
    env_file: .env
    
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow_postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'
      AIRFLOW__WEBSERVER__WORKERS: '1'
      # Environment variables for DAGs
      AWS_REGION: ${AWS_REGION}
      FORMS_BUCKET: ${FORMS_BUCKET}
      S3_ENDPOINT_URL: ${S3_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      MONGODB_URI: mongodb://mongodb:27017/forms
    volumes:
      - ./airflow/dags:/opt/airflow/dags:rw
      - ./airflow/logs:/opt/airflow/logs:rw
      - ./airflow/plugins:/opt/airflow/plugins:rw
      - ./crawler/app:/opt/airflow/crawler/app:ro
      - ./api/app:/opt/airflow/api/app:ro
      - ./worker/app:/opt/airflow/worker/app:ro
    ports:
      - "8080:8080"
    command: webserver
    depends_on:
      airflow_postgres:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    networks: [backend]
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Airflow scheduler
  airflow_scheduler:
    build: ./airflow
    container_name: airflow_scheduler
    env_file: .env
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow_postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'
      # Environment variables for DAGs
      AWS_REGION: ${AWS_REGION}
      FORMS_BUCKET: ${FORMS_BUCKET}
      S3_ENDPOINT_URL: ${S3_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      MONGODB_URI: mongodb://mongodb:27017/forms
      FORMS_QUEUE_URL: ${FORMS_QUEUE_URL}
    volumes:
      - ./airflow/dags:/opt/airflow/dags:rw
      - ./airflow/logs:/opt/airflow/logs:rw
      - ./airflow/plugins:/opt/airflow/plugins:rw
      - ./crawler/app:/opt/airflow/crawler/app:ro
      - ./api/app:/opt/airflow/api/app:ro
      - ./worker/app:/opt/airflow/worker/app:ro
    command: scheduler
    depends_on:
      airflow_postgres:
        condition: service_healthy
      airflow_webserver:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    networks: [backend]
    restart: always
